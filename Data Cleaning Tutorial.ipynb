{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48ae52ca-ca54-4b5a-a1ab-0c8947b4bc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load up store_income_data_task.csv\n",
    "income_df = pd.read_table('store_income_data_task.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa997bbe-d14c-42f4-9bfd-d1c7bc8a1ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for display unique values\n",
    "def display_unique_values(income_df, column_name):\n",
    "    # Exclude empty string values\n",
    "    unique_values = income_df[column_name][income_df[column_name] != ''].unique()\n",
    "    print(f\"There are {len(unique_values)} unique values in the '{column_name}' column.\")\n",
    "    print(f\"Unique values:\\n{unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdc436c5-d02e-4209-88df-046cef717a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 77 unique values in the 'country' column.\n",
      "Unique values:\n",
      "['United States/' 'Britain' ' United States' 'Britain/' ' United Kingdom'\n",
      " 'U.K.' 'SA ' 'U.K/' 'America' 'United Kingdom' nan 'united states'\n",
      " ' S.A.' 'England ' 'UK' 'S.A./' 'ENGLAND' 'BRITAIN' 'U.K' 'U.K '\n",
      " 'America/' 'SA.' 'S.A. ' 'u.k' 'uk' ' ' 'UK.' 'England/' 'england'\n",
      " ' Britain' 'united states of america' 'UK/' 'SA/' 'SA' 'England.'\n",
      " 'UNITED KINGDOM' 'America.' 'S.A..' 's.a.' ' U.K'\n",
      " ' United States of America' 'Britain ' 'England' ' SA'\n",
      " 'United States of America.' 'United States of America/' 'United States.'\n",
      " 's. africasouth africa' ' England' 'United Kingdom '\n",
      " 'United States of America ' ' UK' 'united kingdom' 'AMERICA' 'America '\n",
      " 'UNITED STATES OF AMERICA' ' S. AfricaSouth Africa' 'america'\n",
      " 'S. AFRICASOUTH AFRICA' 'Britain.' '/' 'United Kingdom.' 'United States'\n",
      " ' America' 'UNITED STATES' 'sa' 'United States of America' 'UK '\n",
      " 'United States ' 'S. AfricaSouth Africa/' 'S.A.' 'United Kingdom/'\n",
      " 'S. AfricaSouth Africa ' 'S. AfricaSouth Africa.' 'S. AfricaSouth Africa'\n",
      " '.' 'britain']\n"
     ]
    }
   ],
   "source": [
    "# Display unique countries information (Exclude empty string values)\n",
    "display_unique_values(income_df, 'country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ebb7a1e-0405-4016-9663-9027474d272e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9 unique values in the 'country' column.\n",
      "Unique values:\n",
      "['united states' 'britain' 'united kingdom' 'uk' 'sa' 'america' 'england'\n",
      " 'united states of america' 's africasouth africa']\n"
     ]
    }
   ],
   "source": [
    "# Convert to lower case\n",
    "income_df['country'] = income_df['country'].str.lower()\n",
    "\n",
    "# Remove trailing white spaces\n",
    "income_df['country'] = income_df['country'].str.strip()\n",
    "\n",
    "# Remove all symbols\n",
    "income_df['country'] = income_df['country'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "# Replace NaN values with empty strings\n",
    "income_df['country'] = income_df['country'].fillna(\"\")\n",
    "\n",
    "# Display unique countries information (Exclude empty string values)\n",
    "display_unique_values(income_df, 'country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b994d37-53f2-4e18-ab17-04c1fe9d6c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display unique values before cleaning\n",
      "                    country          country_original  count\n",
      "0                                                         86\n",
      "1                   america                   america     75\n",
      "2                   britain                   britain     95\n",
      "3                   england                   england     76\n",
      "4      s africasouth africa      s africasouth africa     76\n",
      "5                        sa                        sa    184\n",
      "6                        uk                        uk    170\n",
      "7            united kingdom            united kingdom     90\n",
      "8             united states             united states     81\n",
      "9  united states of america  united states of america     67\n"
     ]
    }
   ],
   "source": [
    "# Backup country column for verification later \n",
    "income_df['country_original'] = income_df['country']\n",
    "\n",
    "# Display unique values before cleaning\n",
    "income_df[['country', 'country_original']]\n",
    "grouped = income_df.groupby(['country', 'country_original']).size().reset_index(name='count')\n",
    "\n",
    "print('Display unique values before cleaning')\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0260fbe0-9da4-49c0-a1e3-fcda417ea5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    country          country_original  count\n",
      "5                        sa                        sa    184\n",
      "6                        uk                        uk    170\n",
      "2                   britain                   britain     95\n",
      "7            united kingdom            united kingdom     90\n",
      "0                                                         86\n",
      "8             united states             united states     81\n",
      "4      s africasouth africa      s africasouth africa     76\n",
      "3                   england                   england     76\n",
      "1                   america                   america     75\n",
      "9  united states of america  united states of america     67\n"
     ]
    }
   ],
   "source": [
    "# Display unique values in descending order of occurence\n",
    "grouped = income_df.groupby(['country', 'country_original']).size().reset_index(name='count')\n",
    "sorted_grouped = grouped.sort_values(by='count', ascending=False)\n",
    "\n",
    "print(sorted_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c97031f-00f6-44e5-81ed-6f5bbb40e676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display unique values after fuzzywuzzy cleaning\n",
      "          country          country_original  count\n",
      "0                                               86\n",
      "1         america                   america     75\n",
      "2         britain                   britain     95\n",
      "3         england                   england     76\n",
      "4              sa                        sa    184\n",
      "5    south africa      s africasouth africa     76\n",
      "6              uk                        uk    170\n",
      "7  united kingdom            united kingdom     90\n",
      "8   united states             united states     81\n",
      "9   united states  united states of america     67\n"
     ]
    }
   ],
   "source": [
    "# Function to replace rows in the provided column of the provided DataFrame\n",
    "# that match the provided string above the provided ratio with the provided string\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Define a function to replace similar values\n",
    "def replace_similar_values(income_df, column, target_value, threshold=90):\n",
    "    unique_values = income_df[column].unique()\n",
    "    matches = process.extract(target_value, unique_values, limit=None)\n",
    "    similar_values = [match[0] for match in matches if match[1] >= threshold]\n",
    "    income_df[column] = income_df[column].replace(similar_values, target_value)\n",
    "\n",
    "# Apply the function to consolidate country names\n",
    "replace_similar_values(income_df, 'country', 'united states')\n",
    "replace_similar_values(income_df, 'country', 'south africa')\n",
    "\n",
    "# Verify country with the backup\n",
    "income_df[['country', 'country_original']]\n",
    "grouped = income_df.groupby(['country', 'country_original']).size().reset_index(name='count')\n",
    "\n",
    "print('Display unique values after fuzzywuzzy cleaning')\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "101728e9-9c8f-4fa8-84e5-f82c5a0d4596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "united kingdom              431\n",
      "south africa                260\n",
      "united states of america    223\n",
      "                             86\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define a mapping of old values to new values\n",
    "mapping = {\n",
    "    'uk':                   'united kingdom',\n",
    "    'britain':              'united kingdom',\n",
    "    'england':              'united kingdom',\n",
    "    'united kingdom':       'united kingdom',\n",
    "\t'sa':                   'south africa',\n",
    "\t'united states':        'united states of america',\n",
    "\t'america':              'united states of america'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'country' column\n",
    "income_df['country'] = income_df['country'].replace(mapping)\n",
    "\n",
    "# Verify the result\n",
    "print(income_df['country'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "977061de-3e26-49ca-805a-1bbff953171e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display unique values after mapping cleaning for eyeball check\n",
      "                    country          country_original  count\n",
      "0                                                         86\n",
      "1              south africa      s africasouth africa     76\n",
      "2              south africa                        sa    184\n",
      "3            united kingdom                   britain     95\n",
      "4            united kingdom                   england     76\n",
      "5            united kingdom                        uk    170\n",
      "6            united kingdom            united kingdom     90\n",
      "7  united states of america                   america     75\n",
      "8  united states of america             united states     81\n",
      "9  united states of america  united states of america     67\n"
     ]
    }
   ],
   "source": [
    "# Verify country with the backup\n",
    "income_df[['country', 'country_original']]\n",
    "grouped = income_df.groupby(['country', 'country_original']).size().reset_index(name='count')\n",
    "\n",
    "print('Display unique values after mapping cleaning for eyeball check')\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "674ff60a-4fdf-4145-ab56-fe47191791cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After verification of cleaned country, drop column country_original\n",
    "income_df.drop(columns=['country_original'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82c20345-c078-4bad-81ee-a8f2c4d99a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 unique values in the 'country' column.\n",
      "Unique values:\n",
      "['united states of america' 'united kingdom' 'south africa']\n"
     ]
    }
   ],
   "source": [
    "# Display unique countries information\n",
    "display_unique_values(income_df, 'country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c31db38f-d34d-4976-9f0e-442f4ad7d22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no NaT entries after parsing date_measured, i.e. date parsing is successful for all records.\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "from datetime import date\n",
    "\n",
    "# Create column, days_ago, by using current date minus parsed date_measured\n",
    "income_df['days_ago'] = (pd.to_datetime(date.today()) - pd.to_datetime(income_df['date_measured'], dayfirst=True, errors='coerce')).dt.days\n",
    "\n",
    "# Identify rows with NaT entries\n",
    "err_entries = income_df[income_df['days_ago'].isna()]\n",
    "\n",
    "# Reminder message for data analyst\n",
    "if len(err_entries) > 0:\n",
    "    print(f\"No. of NaT entries: {len(err_entries)};  REMEMBER TO FOLLOW UP!\")\n",
    "    # Display the rows with NaT entries\n",
    "    print(err_entries[['id','days_ago','date_measured']])\n",
    "else:\n",
    "    print(\"There is no NaT entries after parsing date_measured, i.e. date parsing is successful for all records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c072de5-5c74-471e-a7cf-287aa3c7770e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_name</th>\n",
       "      <th>store_email</th>\n",
       "      <th>department</th>\n",
       "      <th>income</th>\n",
       "      <th>date_measured</th>\n",
       "      <th>country</th>\n",
       "      <th>days_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cullen/Frost Bankers, Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>$54438554.24</td>\n",
       "      <td>4-2-2006</td>\n",
       "      <td>united states of america</td>\n",
       "      <td>6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Nordson Corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tools</td>\n",
       "      <td>$41744177.01</td>\n",
       "      <td>4-1-2006</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>6956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Stag Industrial, Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>$36152340.34</td>\n",
       "      <td>12-9-2003</td>\n",
       "      <td>united states of america</td>\n",
       "      <td>7801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FIRST REPUBLIC BANK</td>\n",
       "      <td>ecanadine3@fc2.com</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>$8928350.04</td>\n",
       "      <td>8-5-2006</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>6832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Mercantile Bank Corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Baby</td>\n",
       "      <td>$33552742.32</td>\n",
       "      <td>21-1-1973</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>18992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Auburn National Bancorporation, Inc.</td>\n",
       "      <td>ccaldeyroux5@dion.ne.jp</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>$69798987.04</td>\n",
       "      <td>19-9-1999</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>9255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Interlink Electronics, Inc.</td>\n",
       "      <td>orodenborch6@skyrock.com</td>\n",
       "      <td>Garden</td>\n",
       "      <td>$22521052.79</td>\n",
       "      <td>8-6-2001</td>\n",
       "      <td>south africa</td>\n",
       "      <td>8627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Tallgrass Energy Partners, LP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>$54405380.40</td>\n",
       "      <td>16-9-1992</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>11814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Tronox Limited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Outdoors</td>\n",
       "      <td>$99290004.13</td>\n",
       "      <td>11-1-1992</td>\n",
       "      <td>united states of america</td>\n",
       "      <td>12063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Synopsys, Inc.</td>\n",
       "      <td>lcancellieri9@tmall.com</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>$44091294.62</td>\n",
       "      <td>11-7-2006</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>6768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Hercules Capital, Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>$91009365.11</td>\n",
       "      <td>12-2-1994</td>\n",
       "      <td></td>\n",
       "      <td>11300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>TrustCo Bank Corp NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Garden</td>\n",
       "      <td>$24853409.58</td>\n",
       "      <td>8-3-1993</td>\n",
       "      <td>united states of america</td>\n",
       "      <td>11641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Canadian Pacific Railway Limited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>$65184489.16</td>\n",
       "      <td>24-8-1966</td>\n",
       "      <td></td>\n",
       "      <td>21334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Copart, Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kids</td>\n",
       "      <td>$54371540.24</td>\n",
       "      <td>14-2-2005</td>\n",
       "      <td>south africa</td>\n",
       "      <td>7280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Autoliv, Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Music</td>\n",
       "      <td>$25747934.59</td>\n",
       "      <td>15-1-1986</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>14250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>New Home Company Inc. (The)</td>\n",
       "      <td>nhinchcliffef@whitehouse.gov</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>$90808764.99</td>\n",
       "      <td>21-4-1993</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>11597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>First Financial Corporation Indiana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>$26955392.71</td>\n",
       "      <td>20-8-2007</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>6363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Royal Bank Scotland plc (The)</td>\n",
       "      <td>clernihanh@google.cn</td>\n",
       "      <td>Music</td>\n",
       "      <td>$2290913.13</td>\n",
       "      <td>22-11-2002</td>\n",
       "      <td>south africa</td>\n",
       "      <td>8095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Vulcan Materials Company</td>\n",
       "      <td>croxburghi@ed.gov</td>\n",
       "      <td>Health</td>\n",
       "      <td>$8888812.21</td>\n",
       "      <td>8-9-2009</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>5613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Methanex Corporation</td>\n",
       "      <td>bsussansj@google.es</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$20201805.61</td>\n",
       "      <td>7-4-2009</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>5767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                            store_name                   store_email  \\\n",
       "0    1            Cullen/Frost Bankers, Inc.                           NaN   \n",
       "1    2                   Nordson Corporation                           NaN   \n",
       "2    3                 Stag Industrial, Inc.                           NaN   \n",
       "3    4                   FIRST REPUBLIC BANK            ecanadine3@fc2.com   \n",
       "4    5           Mercantile Bank Corporation                           NaN   \n",
       "5    6  Auburn National Bancorporation, Inc.       ccaldeyroux5@dion.ne.jp   \n",
       "6    7           Interlink Electronics, Inc.      orodenborch6@skyrock.com   \n",
       "7    8         Tallgrass Energy Partners, LP                           NaN   \n",
       "8    9                        Tronox Limited                           NaN   \n",
       "9   10                        Synopsys, Inc.       lcancellieri9@tmall.com   \n",
       "10  11                Hercules Capital, Inc.                           NaN   \n",
       "11  12                  TrustCo Bank Corp NY                           NaN   \n",
       "12  13      Canadian Pacific Railway Limited                           NaN   \n",
       "13  14                          Copart, Inc.                           NaN   \n",
       "14  15                         Autoliv, Inc.                           NaN   \n",
       "15  16           New Home Company Inc. (The)  nhinchcliffef@whitehouse.gov   \n",
       "16  17   First Financial Corporation Indiana                           NaN   \n",
       "17  18         Royal Bank Scotland plc (The)          clernihanh@google.cn   \n",
       "18  19              Vulcan Materials Company             croxburghi@ed.gov   \n",
       "19  20                  Methanex Corporation           bsussansj@google.es   \n",
       "\n",
       "     department        income date_measured                   country  \\\n",
       "0      Clothing  $54438554.24      4-2-2006  united states of america   \n",
       "1         Tools  $41744177.01      4-1-2006            united kingdom   \n",
       "2        Beauty  $36152340.34     12-9-2003  united states of america   \n",
       "3    Automotive   $8928350.04      8-5-2006            united kingdom   \n",
       "4          Baby  $33552742.32     21-1-1973            united kingdom   \n",
       "5       Grocery  $69798987.04     19-9-1999            united kingdom   \n",
       "6        Garden  $22521052.79      8-6-2001              south africa   \n",
       "7       Grocery  $54405380.40     16-9-1992            united kingdom   \n",
       "8      Outdoors  $99290004.13     11-1-1992  united states of america   \n",
       "9   Electronics  $44091294.62     11-7-2006            united kingdom   \n",
       "10       Beauty  $91009365.11     12-2-1994                             \n",
       "11       Garden  $24853409.58      8-3-1993  united states of america   \n",
       "12  Electronics  $65184489.16     24-8-1966                             \n",
       "13         Kids  $54371540.24     14-2-2005              south africa   \n",
       "14        Music  $25747934.59     15-1-1986            united kingdom   \n",
       "15        Shoes  $90808764.99     21-4-1993            united kingdom   \n",
       "16  Electronics  $26955392.71     20-8-2007            united kingdom   \n",
       "17        Music   $2290913.13    22-11-2002              south africa   \n",
       "18       Health   $8888812.21      8-9-2009            united kingdom   \n",
       "19          NaN  $20201805.61      7-4-2009            united kingdom   \n",
       "\n",
       "    days_ago  \n",
       "0       6925  \n",
       "1       6956  \n",
       "2       7801  \n",
       "3       6832  \n",
       "4      18992  \n",
       "5       9255  \n",
       "6       8627  \n",
       "7      11814  \n",
       "8      12063  \n",
       "9       6768  \n",
       "10     11300  \n",
       "11     11641  \n",
       "12     21334  \n",
       "13      7280  \n",
       "14     14250  \n",
       "15     11597  \n",
       "16      6363  \n",
       "17      8095  \n",
       "18      5613  \n",
       "19      5767  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display cleaned data of the first 20 records\n",
    "income_df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
